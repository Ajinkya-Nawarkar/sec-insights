#pull the latest llama3
ollama pull llama3.2

#run it locally
ollama run llama3.2

# to get webUI
sudo docker run -d --network=host -e OLLAMA_BASE_URL=http://127.0.0.1:11434 -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main

#launch UI to by connecting to 127.0.0.1:8080 via browser. 
#It may ask you fist time setup credentials, etc., and you should be able to select the model 
#from the drop down box and UI allows uploading a PDF
